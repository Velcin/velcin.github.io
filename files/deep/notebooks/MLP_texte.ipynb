{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD2 : classification de données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a été développé dans le cours donné par J. Velcin sur le Deep Learning à l'Université de Lyon 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par charger en mémoire les données spam diffusée à l'occasion du tutoriel de A. Gramfort et A. Mueller à SciPy 2017\n",
    "https://github.com/amueller/scipy-2017-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"datasets\", \"smsspam\", \"SMSSpamCollection\")) as f:\n",
    "    lines = [line.strip().split(\"\\t\") for line in f.readlines()]\n",
    "\n",
    "text = [x[1] for x in lines]\n",
    "y = [int(x[0] == \"spam\") for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\"]\n",
      "[0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(text[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La bibliothèque scikit-learn fournit des commandes très utiles pour vectoriser le texte, cf. tutoriel SciPy 2017 et cours de text mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorize_spamdata = TfidfVectorizer()\n",
    "vectorize_spamdata.fit(text)\n",
    "data = vectorize_spamdata.transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8716)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = data.shape[1]\n",
    "print(data.shape)\n",
    "data[10:20, 4:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare le jeu de données en ensemble d'entraînement et de test en conservant un équilibre dans les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit un simple MLP avec une couche cachée, cf. TD 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 8)                 69736     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,745\n",
      "Trainable params: 69,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_mlp = mlp()\n",
    "simple_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a besoin de convertir la liste en tableau numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array(test_y)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On lance l'apprentissage sur 10 epochs avec des batch de 10 textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 11/391 [..............................] - ETA: 2s - loss: 0.6809 - accuracy: 0.8455  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 09:20:56.891798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4046 - accuracy: 0.8721\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.1524 - accuracy: 0.9549\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0736 - accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0440 - accuracy: 0.9923\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0290 - accuracy: 0.9949\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0202 - accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9982\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6ccb7f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_mlp.fit(train_X, train_y, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons les résultats en généralisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/53 [=================>............] - ETA: 0s - loss: 0.0595 - accuracy: 0.9848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 09:22:14.011956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9869\n",
      "test score:  0.051393888890743256\n",
      "test accuracy:  0.9868500232696533\n"
     ]
    }
   ],
   "source": [
    "score = simple_mlp.evaluate(test_X, test_y)\n",
    "print(\"test score: \", score[0])\n",
    "print(\"test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour information, la régression logistique atteint ~96% de réussite sur le même jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.13646051,  0.179735  , -0.10603371, ...,  0.13543199,\n",
       "         -0.08062363, -0.07995619],\n",
       "        [ 0.22492523,  0.33349097, -0.16878554, ...,  0.23677073,\n",
       "         -0.15987249, -0.15640791],\n",
       "        [-0.02432143, -0.02261983,  0.03619136, ..., -0.03094219,\n",
       "          0.049872  ,  0.02965823],\n",
       "        ...,\n",
       "        [-0.00252159,  0.01166426,  0.01861603, ..., -0.00199095,\n",
       "          0.04667639,  0.04463157],\n",
       "        [ 0.10752779,  0.08941199, -0.1062703 , ...,  0.08843637,\n",
       "         -0.0732681 , -0.10260005],\n",
       "        [-0.06009427, -0.05941159,  0.05423395, ..., -0.0587045 ,\n",
       "          0.0473928 ,  0.05170109]], dtype=float32),\n",
       " array([0.16885541, 0.18907182, 0.4353391 , 0.4006136 , 0.48576194,\n",
       "        0.15885757, 0.4409305 , 0.40575182], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_mlp.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
