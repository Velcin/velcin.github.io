{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=6>**TD 3 : plongement de mots avec spacy**</font>\n",
    "\n",
    "Julien Velcin, Université Lyon 2 - Master Humanités Numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook est juste une petite démonstration de l'utilisation des plongements de mots (statiques) à l'aide de la libraire spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au préalable, il faut (bien sûr) avoir installé la [librairie spacy](https://spacy.io/usage) mais il faut également penser à télécharger l'ensemble des vecteurs associés, ce qu'on appelle la version \"large\" de la base de données (cf. le \"lg\" à la fin).\n",
    "\n",
    "Commande à lancer en console :\n",
    "\n",
    "*python -m spacy download fr_core_news_lg*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies\n",
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# on charge la ressource linguistique\n",
    "nlp = spacy.load('fr_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction *find_close_words* cherche les mots les plus similaires dans l'espace vectoriel des plongements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_close_words(word):\n",
    "    sim_words = nlp.vocab.vectors.most_similar(\n",
    "        np.asarray([nlp.vocab.vectors[nlp.vocab.strings[word]]]), n=10)\n",
    "    return [nlp.vocab.strings[w] for w in sim_words[0][0]]\n",
    "\n",
    "# attention, nlp.vocab.strings fonctionne dans les deux sens :\n",
    "#  - retourne l'identifiant (unique) correspondant à un mot\n",
    "#  - retourne le mot correspondant à un identifiant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roi',\n",
       " 'Roi',\n",
       " 'prince',\n",
       " 'monarque',\n",
       " 'empereur',\n",
       " 'régent',\n",
       " 'Empereur',\n",
       " 'suzerain',\n",
       " 'coempereur',\n",
       " 'l\\x92empereur']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_close_words(\"roi\")\n",
    "#find_close_words(\"café\")\n",
    "#find_close_words(\"deux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également calculer des similarités entre mots grâce à la fonction *similarity* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entre roi et reine : 0.628108097894871\n",
      "entre roi et trône : 0.6489303722402299\n",
      "entre roi et oiseau : 0.10113929594015392\n"
     ]
    }
   ],
   "source": [
    "print(\"entre roi et reine : {}\".format(nlp(\"roi\").similarity(nlp(\"reine\"))))\n",
    "print(\"entre roi et trône : {}\".format(nlp(\"roi\").similarity(nlp(\"trône\"))))\n",
    "print(\"entre roi et oiseau : {}\".format(nlp(\"roi\").similarity(nlp(\"oiseau\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vecteurs associés aux mots sont directement accessibles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.6351e+00, -4.7504e+00,  2.9866e+00, -6.5048e-02,  5.6314e+00,\n",
       "       -2.6488e+00,  1.6728e+00,  3.6799e+00,  2.2033e+00, -2.3401e-01,\n",
       "        1.7170e+00, -3.0931e+00,  3.8267e+00,  1.8726e-01, -2.2761e+00,\n",
       "       -2.1582e+00,  3.8331e+00, -1.1703e-01,  1.2575e+00,  3.2968e+00,\n",
       "       -1.1991e+00,  5.0724e-01, -2.6204e+00,  2.1288e+00,  9.9307e-01,\n",
       "       -3.1832e+00, -2.3930e+00,  1.3869e+00, -1.7312e+00,  4.5163e+00,\n",
       "        9.9608e-01, -3.1276e+00, -1.5539e+00,  1.0525e+00, -5.3267e-01,\n",
       "       -5.5565e+00,  8.4429e-01,  4.9819e+00, -4.6006e-01,  2.2781e+00,\n",
       "       -1.0639e+00,  1.2235e+00, -4.5606e+00,  3.4419e-01,  1.9167e+00,\n",
       "       -1.5078e+00,  3.6443e+00,  2.8392e+00,  4.9837e-01, -5.5096e-02,\n",
       "       -7.9940e+00, -1.9028e+00, -3.9536e+00,  3.7232e-03,  2.3186e+00,\n",
       "        5.6297e+00,  2.2466e+00,  5.2483e-01,  1.2710e+00, -5.8875e-01,\n",
       "       -2.2971e+00,  1.4909e-01,  2.7780e-03,  3.9281e+00,  6.5166e-01,\n",
       "        8.9464e-02,  3.2467e+00,  9.5456e-01, -2.4231e+00, -4.3828e+00,\n",
       "        1.2746e+00,  1.8955e+00, -2.9509e+00, -5.8867e+00,  3.0693e+00,\n",
       "       -8.0891e-01,  6.9400e-01,  3.8128e+00,  3.5806e+00,  4.2890e+00,\n",
       "       -2.7194e+00,  2.5940e+00,  4.6594e+00,  6.6699e-02, -4.7390e+00,\n",
       "       -1.4998e-01, -9.3746e-01,  4.6751e+00, -1.4972e+00, -1.0867e+01,\n",
       "        4.9722e+00, -3.9660e-01,  9.2787e-01,  4.9520e-01,  2.4602e+00,\n",
       "       -1.0434e+00,  3.0316e+00, -1.7612e-02,  4.9520e+00, -4.8073e+00,\n",
       "        3.8922e-01,  1.0257e+00,  1.0831e-01,  4.0534e+00, -2.1833e+00,\n",
       "        1.5790e+00, -3.2116e+00,  2.6927e+00, -3.8434e-01, -4.7468e+00,\n",
       "        7.2697e-01, -2.1205e+00,  5.9403e-01,  4.7841e+00, -3.8717e+00,\n",
       "       -3.0401e+00, -1.2210e+00, -2.8635e+00, -6.9869e-01,  3.2319e+00,\n",
       "        5.7720e+00,  5.9429e+00, -4.3025e+00, -4.9565e-01, -2.3339e+00,\n",
       "       -1.5692e+00, -6.8929e-01, -1.1271e+00, -1.3472e+00,  2.0474e+00,\n",
       "        4.7208e+00, -4.9401e-01,  1.2751e+00, -3.2224e+00, -1.0313e+00,\n",
       "       -1.7439e+00,  8.7939e-01,  1.2688e-01, -4.7297e+00, -1.5638e+00,\n",
       "       -2.3903e+00,  9.2193e-01,  1.1045e+00, -2.1525e+00,  9.6714e-01,\n",
       "        1.3308e+00, -5.6572e+00, -2.5758e+00,  3.4210e+00,  1.8027e+00,\n",
       "        6.2324e+00,  5.7700e+00,  2.3663e+00,  1.0878e+00, -1.3365e+00,\n",
       "        1.1781e+00,  2.7440e+00,  2.3066e+00,  8.4879e-01,  2.2804e+00,\n",
       "        1.5781e+00, -2.4117e+00, -1.3357e+00,  5.1102e+00, -8.7586e-01,\n",
       "       -2.9436e+00, -1.9356e+00,  7.7401e+00,  5.9926e+00,  2.3883e+00,\n",
       "       -3.1656e+00,  6.4872e+00, -2.2768e+00,  1.4991e+00, -3.8998e+00,\n",
       "        5.2592e-01, -3.8706e-01, -9.6823e-01,  1.4808e+00, -3.9378e+00,\n",
       "       -2.0357e+00, -4.4986e+00,  8.9750e+00,  2.2045e+00,  1.8716e-03,\n",
       "        3.2258e+00,  4.7617e+00, -1.8651e+00, -6.1514e+00,  2.5549e+00,\n",
       "       -1.6786e+00,  1.9050e+00,  3.4051e+00, -4.6565e+00,  4.1841e+00,\n",
       "       -7.8164e+00,  1.6226e+00, -2.7039e+00, -5.7035e-01, -1.3518e+00,\n",
       "       -8.5385e-01, -1.2273e+00,  1.2349e+00, -7.8515e-01,  5.0479e-01,\n",
       "        2.8719e+00,  8.9905e-01,  4.9693e+00, -2.0078e+00,  4.3517e+00,\n",
       "       -1.6480e+00, -5.0611e+00,  6.5107e+00, -3.6784e+00,  3.1451e+00,\n",
       "       -2.8814e+00, -3.1464e+00, -1.5150e-01,  3.1440e+00, -3.6309e+00,\n",
       "       -2.3865e+00,  4.2842e+00,  2.9188e+00, -2.8959e+00,  8.5420e-01,\n",
       "        6.1502e+00,  3.0970e+00, -6.2933e-02, -7.2427e-01, -4.6472e+00,\n",
       "       -5.1277e-01,  3.6802e+00,  4.1581e+00,  1.6980e+00,  3.4822e+00,\n",
       "        1.8467e+00, -2.8244e+00, -8.6421e+00,  1.9419e+00, -2.4484e-01,\n",
       "        2.5395e+00, -2.6593e+00, -2.9772e+00, -1.7609e+00, -1.1823e+00,\n",
       "        6.7310e+00,  2.8250e+00, -2.4596e-01, -4.1260e+00,  4.5138e+00,\n",
       "       -5.3808e+00, -2.3224e+00,  1.9299e+00,  1.6637e+00,  5.3128e+00,\n",
       "       -2.1047e+00, -1.5359e+00, -2.2614e-01, -8.1183e+00,  3.4033e-01,\n",
       "        1.6500e+00, -2.3227e+00,  4.0308e+00,  3.5514e+00,  6.6944e-01,\n",
       "        1.4120e+00, -8.0441e-01, -6.5361e-01, -5.6505e+00,  2.4682e+00,\n",
       "       -9.1946e+00, -6.3852e+00,  8.2396e+00, -2.7895e+00, -2.3564e+00,\n",
       "        8.4714e+00, -2.6244e-01,  4.2987e+00,  1.5561e+00,  2.4657e+00,\n",
       "       -6.1948e+00, -6.6181e-01, -9.9525e-01,  4.2478e+00, -6.1932e+00,\n",
       "       -1.9624e+00, -7.0235e+00,  3.3948e-01, -7.3027e-01, -4.2027e+00,\n",
       "        1.5683e+00, -6.5984e+00, -2.5014e+00,  1.3260e+00, -3.1824e+00,\n",
       "       -5.0466e+00, -5.4672e+00, -4.6966e+00, -5.3983e+00,  1.5300e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"roi\").vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut même résoudre des problèmes d'analogie. Par ex., qu'est-ce qui est à \"femme\" ce que \"homme\" est à \"roi\" ? Ou la relation \"capitale de\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction *close_words_from_vector* retourne les *k* mots les plus similaires au vecteur *vec* donné en entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_words_from_vector(vec, k=10):\n",
    "    ms = nlp.vocab.vectors.most_similar(np.array([vec]), n=k)\n",
    "    return [nlp.vocab.strings[w] for w in ms[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'opération est : v_roi - v_homme + v_femme (cf. cours) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roi',\n",
       " 'reine',\n",
       " 'Roi',\n",
       " 'prince',\n",
       " 'régent',\n",
       " 'duc',\n",
       " 'princesse',\n",
       " 'monarque',\n",
       " 'suzerain',\n",
       " 'coempereur']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogie = nlp(\"roi\").vector-nlp(\"homme\").vector+nlp(\"femme\").vector\n",
    "close_words_from_vector(analogie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allemagne',\n",
       " 'europe',\n",
       " 'france',\n",
       " 'amérique',\n",
       " 'l´Allemagne',\n",
       " 'afrique',\n",
       " 'dafrique',\n",
       " 'espagne',\n",
       " 'autriche',\n",
       " 'lafrique']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogie = nlp(\"france\").vector-nlp(\"paris\").vector+nlp(\"berlin\").vector\n",
    "close_words_from_vector(analogie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['musique',\n",
       " 'pusique',\n",
       " 'Aramusique',\n",
       " 'photographie',\n",
       " 'sculture',\n",
       " 'culture',\n",
       " 'kulture',\n",
       " 'contre-culture',\n",
       " 'musicalité',\n",
       " 'contemporaine']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogie = nlp(\"musique\").vector-nlp(\"mozart\").vector+nlp(\"picasso\").vector\n",
    "close_words_from_vector(analogie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi travailler à partir de plusieurs mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['données',\n",
       " 'd‘informations',\n",
       " 'quantifications',\n",
       " 'nformations',\n",
       " 'informations',\n",
       " 'connaissances',\n",
       " 'd´informations',\n",
       " 'identifications',\n",
       " 'désinformations',\n",
       " 'authentifications']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ph = nlp(\"science\").vector\n",
    "ph = nlp(\"données science\").vector\n",
    "close_words_from_vector(ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir, lien vers une visualisation intéressante :\n",
    "\n",
    "http://projector.tensorflow.org"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
