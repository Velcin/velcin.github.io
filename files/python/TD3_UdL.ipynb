{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à la programmation Python\n",
    "\n",
    "Julien Velcin, Université Lyon 2\n",
    "\n",
    "Formation doctorale de l'UdL (2022-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TP n°3 : de la chaîne de caractères au sac de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Differentes manières de représenter des données textuelles\n",
    "\n",
    "- Chaîne de caractères (string)\n",
    "- Bag-of-Words (BoW)\n",
    "- Vector Space Model (VSM)\n",
    "- Ajouter des méta-données (par ex. catégories grammaticales)\n",
    "- Représentations plus complexes : arbres syntaxiques, graphes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Chaque représentation implique une manière différente de *comparer* les documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Un exemple très simple\n",
    "\n",
    "*\"John Doe has bought an apple.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Point de vue linguistique:\n",
    "\n",
    "<table style=\"border:0;\">\n",
    "<tr style=\"border:0;\">\n",
    "<td style=\"border:0; white-space:pre; padding:0 100px 0 0px;\">\"John Doe has bought an apple.\"</td>\n",
    "<td style=\"border:0;\"><img src=\"img/syntaxtree.png\" style='height: 150px'/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Point de vue statistique :\n",
    "\n",
    "<img src=\"img/bow-illu.png\" style='height: 150px'/>\n",
    "\n",
    "<table style=\"border:0;\">\n",
    "<tr style=\"border:0;\">\n",
    "<td style=\"border:0; white-space:pre; padding:0 100px 0 0px;\">\"John Doe has bought an apple.\"</td>\n",
    "<td style=\"border:0;\">{ apple,<br/><br/> bought,<br/><br/>John_Doe } </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/bow.png\" style='height: 400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut déjà observer des problèmes évidents, tel que :\n",
    "\n",
    "*\"Mary asked Fred out.\"*\n",
    "<br/>\n",
    "*\"Fred asked Mary out.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La représentation est la même :\n",
    "<img src=\"img/mary.png\" style='height: 200px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A partir d'un *ensemble* de documents, on souhaite obtenir l'objet suivant :\n",
    "<img src=\"img/termdocmatrix.png\" style='height: 300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Par exemple :\n",
    "<img src=\"img/termdocmatrix-2.jpg\" style='width: 400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extraire les caractéristiques des textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En pratique, on utilise le formalisme du \"sac de mots\" et on suit plusieurs étapes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"img/bag_of_words.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Prenons à présent deux documents, tels que :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = [\"Some say the world will end in fire,\",\n",
    "     \"Some say in ice.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La librairie contient une fonction qui permet de \"vectoriser\" un ensemble de textes en prenant en compte un certain nombre de prétraitements (*preprocessing*) couramment employés : mis en minuscule, utilisation de mots-outils, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observons le vocabulaire automatiquement construit à partir de ces deux textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'some': 5,\n",
       " 'say': 4,\n",
       " 'the': 6,\n",
       " 'world': 8,\n",
       " 'will': 7,\n",
       " 'end': 0,\n",
       " 'in': 3,\n",
       " 'fire': 1,\n",
       " 'ice': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Quelques mots sur la présence de mots tels que \"in\" ou \"the\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mots les plus fréquents observés dans Harry Potter :\n",
    "\n",
    "<img src=\"img/zipf_1.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette forme particulière est appelée \"loi de Zipf\". Elle a été observée pour la première fois par le linguiste George K. Zipf (1902-1950).\n",
    "\n",
    "La loi de Zipf indique que si l'on observe un corpus suffisamment grand, la fréquence d'apparition d'un mot est **inversement proportionnelle** à son rang dans la table des fréquences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Même graphique mais en supprimant les mots-outils anglais :\n",
    "    \n",
    "<img src=\"img/zipf_2.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "D'autres prétraitements sont également disponibles, tels que :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* racinisation (stemming) : trouver la racine des mots, comme dans :\n",
    "     \n",
    "> learn: learns, learned, learning...<br/>\n",
    "> march: marcher, marchera, marcherai...\n",
    " \n",
    "* lemmatisation (lemmatization) : trouver le lemme, comme dans :\n",
    "\n",
    "> to be: am, are<br/>\n",
    "> être : suis, sont...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Le stemming nous aide à :\n",
    "\n",
    "- rapprocher deux documents sémantiquement liés mais n'utilisant pas exactement les mêmes termes\n",
    "- réduire la taille du vocabulaire (cf. malédiction de la dimension)\n",
    "\n",
    "Ok pour :\n",
    "\n",
    "    adventur: [adventure,adventurer,adventurers,adventures,adventurous]\n",
    "\n",
    "mais...\n",
    "\n",
    "    anim: [animal, animals, animation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Autre prétraitement utile : remplacer certains motifs trouvés dans les textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some say the world will end in fire,', 'Some say in ice.']\n",
      "['Some say the worlds will end in fire,', 'Some say in ice.']\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "str = [x.replace(\"world\", \"worlds\") for x in X]\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truc truc the world will end in fire,'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(\"[s|S]+\\w*\", \"truc\", X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Corriger automatiquement l'orthographe des mots grâce à la distance d'édition (ou distance Levenshtein, proposée en 1965).\n",
    "Il s'agit de calculer le plus petit nombre d'opérations (insertion, suppression, remplacement) pour passer d'une chaîne à une autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# one possible implementation from https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#levenshtein(\"chaîne\", \"chaine\")\n",
    "#levenshtein(\"chaîne\", \"chiane\")\n",
    "levenshtein(\"remerciement\", \"remerciments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrice documents x termes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut maintenant construire la matrice documents * termes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_bag_of_words = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Jetons un oeil au contenu de la matrice :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On observe que la valeur indiquée dans une cellule est le nombre d'occurrences d'un terme dans un document (TF pour *Term Frequency*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut également retrouver le nom des termes du vocabulaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end', 'fire', 'ice', 'in', 'say', 'some', 'the', 'will', 'world']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut retrouver les attributs (features) utilisés dans les documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['end', 'fire', 'in', 'say', 'some', 'the', 'will', 'world'],\n",
       "       dtype='<U5'),\n",
       " array(['ice', 'in', 'say', 'some'], dtype='<U5')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(X_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Représentation TFxIDF\n",
    "A la place du nombre d'occurrences (TF), on peut utiliser une autre mesure qui prend en compte la rareté d'un mot dans le corpus :\n",
    "\n",
    "$$ tf_{t,d} \\times idf_{t} $$\n",
    "\n",
    "avec $tf_{t,d}$ le nombre d'occurrences de $t$ dans $d$\n",
    "\n",
    "et $idf_{t} = \\log \\frac{N}{df_t}$ ($N$ est le nombre total de documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39 0.39 0.   0.28 0.28 0.28 0.39 0.39 0.39]\n",
      " [0.   0.   0.63 0.45 0.45 0.45 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "X_TFxIDF = tfidf_vectorizer.transform(X)\n",
    "print(X_TFxIDF.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparaison de deux textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Les distances usuelles (ex. euclidenne) ne sont pas adaptées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dans les espaces à **beaucoup de dimensions** :\n",
    "\n",
    "Pourquoi les banquiers n'ont jamais de lingots sphériques ?\n",
    "\n",
    "Pourquoi les marchands d'oranges occupent beaucoup de place pour empiler peu d'oranges ?\n",
    "\n",
    "http://www.brouty.fr/Maths/sphere.html (see \"Curiosités du calcul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Malédiction de la dimension (curse of dimensionality)\n",
    "\n",
    "Richard E. Bellman (1920-1984): les hypervolumes sont presque vides!\n",
    "\n",
    "<img src=\"img/curse.png\" style='height: 400px'/>\n",
    "\n",
    "Un volume avec $dim=d$ a besoin de $10^d$ données pour peupler équitablement l'espace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Produit scalaire et cosinus\n",
    "\n",
    "$\\vec{x}$ et $\\vec{y}$ sont deux vecteurs dans le VSM.\n",
    "\n",
    "Cosine est une mesure de **similarité** calculée sur l'angle formé par les deux vecteurs :\n",
    "\n",
    "$$cos(\\vec{x},\\vec{y}) = \\frac{\\vec{x}.\\vec{y}}{||\\vec{x}||_2 \\times ||\\vec{y}||_2}$$\n",
    "\n",
    "Elle prend une valeur entre 0 (rien en commun) et 1 (même vecteurs à une constante près)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Interprétation géométrique\n",
    "\n",
    "<img src=\"img/cosine.png\" style='height: 300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exemple : distribution des mots les plus fréquents dans Harry Potter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Commençons par lire les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open(os.path.join(\"datasets\", \"Harry_Potter_1.txt\")) as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "tf_vectorizer = CountVectorizer()   \n",
    "#tfidf_vectorizer = TfidfVectorizer()\n",
    "tf_vectorizer.fit(lines)\n",
    "\n",
    "# montrer l'intégralité du vocabulaire (peut être long) :\n",
    "#tf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_hp = tf_vectorizer.transform(lines)\n",
    "features_hp = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut utiliser quelques fonctions pour afficher le vecteur pour un document en particulier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# des options permettent de limiter (ou non) le nombre de lignes/colonnes affichées\n",
    "# par exemple :\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "def top_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids if row[i]>0]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    if len(top_feats) > 0:\n",
    "        df.columns = ['feature', 'score']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_feats(row, features, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>were</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>strange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dursley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>because</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  score\n",
       "0     they      3\n",
       "1     were      3\n",
       "2       to      2\n",
       "3      you      2\n",
       "4    thank      1\n",
       "5  strange      1\n",
       "6  dursley      1\n",
       "7       mr      1\n",
       "8      and      1\n",
       "9  because      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lines[4])\n",
    "\n",
    "top_feats_in_doc(X_hp, features_hp, 4, top_n=10)\n",
    "#top_feats_in_doc(X_hp, features_hp, 6, top_n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les mots les plus fréquents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>3627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harry</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>was</td>\n",
       "      <td>1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>his</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>said</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>had</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>they</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>that</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>on</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>at</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>as</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>him</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>but</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ron</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>with</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>all</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>what</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>out</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  score\n",
       "0      the   3627\n",
       "1      and   1923\n",
       "2       to   1861\n",
       "3       he   1759\n",
       "4    harry   1326\n",
       "5       of   1267\n",
       "6       it   1186\n",
       "7      was   1186\n",
       "8      you   1037\n",
       "9       in    967\n",
       "10     his    937\n",
       "11    said    794\n",
       "12     had    701\n",
       "13    they    691\n",
       "14    that    688\n",
       "15      on    637\n",
       "16      at    625\n",
       "17      as    526\n",
       "18     him    501\n",
       "19     but    485\n",
       "20     ron    429\n",
       "21    with    416\n",
       "22     all    397\n",
       "23    what    386\n",
       "24     out    375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = X_hp.toarray()\n",
    "\n",
    "n_docs, n_terms = D.shape\n",
    "\n",
    "#tf_means = np.mean(D, axis=0)\n",
    "tf_sum = np.sum(D, axis=0)\n",
    "top_feats(tf_sum, features_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Comparer des documents revient à comparer les valeurs de deux colonnes (vecteurs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# fonction calculant le cosinus entre deux vecteurs\n",
    "def cosinus(i, j):\n",
    "    num = np.dot(i, j)\n",
    "    den = math.sqrt(sum(i*i))*math.sqrt(sum(j*j))\n",
    "    if (den>0):    \n",
    "        return (num/den)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature  score\n",
      "0         the      4\n",
      "1         was      4\n",
      "2         and      3\n",
      "3          of      3\n",
      "4          he      2\n",
      "5        very      2\n",
      "6     dursley      2\n",
      "7          in      2\n",
      "8       which      2\n",
      "9      called      2\n",
      "10        had      2\n",
      "11       neck      2\n",
      "12       thin      1\n",
      "13         mr      1\n",
      "14     garden      1\n",
      "15        man      1\n",
      "16      their      1\n",
      "17      beefy      1\n",
      "18        big      1\n",
      "19   director      1\n",
      "20   anywhere      1\n",
      "21       have      1\n",
      "22      there      1\n",
      "23       came      1\n",
      "24      twice      1\n",
      "25       made      1\n",
      "26       much      1\n",
      "27        mrs      1\n",
      "28       firm      1\n",
      "29         on      1\n",
      "30  neighbors      1\n",
      "31        did      1\n",
      "32        she      1\n",
      "33      small      1\n",
      "34      spent      1\n",
      "35  grunnings      1\n",
      "36       over      1\n",
      "37      usual      1\n",
      "38         as      1\n",
      "39    craning      1\n",
      "     feature  score\n",
      "0         he      2\n",
      "1        got      1\n",
      "2       tyke      1\n",
      "3         mr      1\n",
      "4       four      1\n",
      "5       left      1\n",
      "6        his      1\n",
      "7        out      1\n",
      "8     backed      1\n",
      "9         of      1\n",
      "10    number      1\n",
      "11       and      1\n",
      "12     drive      1\n",
      "13   dursley      1\n",
      "14       car      1\n",
      "15  chortled      1\n",
      "16        as      1\n",
      "17       the      1\n",
      "18      into      1\n",
      "19    little      1\n",
      "20     house      1\n"
     ]
    }
   ],
   "source": [
    "print(top_feats_in_doc(X_hp, features_hp, 5, top_n=40))\n",
    "print(top_feats_in_doc(X_hp, features_hp, 10, top_n=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31859654643215496"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosinus(D[5, :], D[10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer son propre moteur de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5600"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_hp.index(\"wizard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[818, 818, 818, 3543, 2246]\n"
     ]
    }
   ],
   "source": [
    "#query = ['privet', 'drive', 'dursley']\n",
    "#query = ['1473', 'aaaaarrrgh']\n",
    "query = ['chess', 'chess', 'chess', 'play', 'harry']\n",
    "\n",
    "indexes = [features_hp.index(q) for q in query if q in features_hp]\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit un vecteur de la même taille que le vocabulaire. Il est initialisé à zéro, puis on y met la valeur 1 pour les termes de la requête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = np.zeros(n_terms)\n",
    "query_vec[indexes] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5707"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(D[10,:])\n",
    "len(query_vec)\n",
    "#query_vec[0:10]\n",
    "#query_vec[3658:3670]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier que le vecteur requête contient bien 3 éléments non nuls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du cosinus vis-à-vis de la requête pour 1 document :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosinus(D[4, :], query_vec)\n",
    "#lines[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On automatise en calculant pour tous les docs et on triant le résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui crée un dictionnaire associant le cosinus à chaque document\n",
    "# puis le trie de manière décroissante\n",
    "\n",
    "def search(q, D):\n",
    "    cc = {i: cosinus(D[i, :], q) for i in range(n_docs)}\n",
    "    cc = sorted(cc.items(), key=lambda x: x[1], reverse=True)\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(query_vec, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2137, 0.6546536707079772),\n",
       " (3135, 0.5773502691896258),\n",
       " (1060, 0.47140452079103173),\n",
       " (129, 0.40824829046386296),\n",
       " (815, 0.40824829046386296),\n",
       " (942, 0.40824829046386296),\n",
       " (970, 0.40824829046386296),\n",
       " (1073, 0.40824829046386296),\n",
       " (1224, 0.40824829046386296),\n",
       " (1352, 0.40824829046386296)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne retient que les dix premiers résultats (par exemple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2137, 3135, 1060, 129, 815, 942, 970, 1073, 1224, 1352]\n"
     ]
    }
   ],
   "source": [
    "nb_top_docs = 10\n",
    "top_docs = [r for (r,v) in result[0:nb_top_docs]]\n",
    "print(top_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir, on peut afficher les textes les plus pertinents pour la requête :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2137): “Want to play chess, Harry?” said Ron.\n",
      "2 (3135): “Harry!”\n",
      "3 (1060): “Harry Potter,” said Harry.\n",
      "4 (129): Harry groaned.\n",
      "5 (815): Harry swallowed.\n",
      "6 (942): “Harry Potter!”\n",
      "7 (970): Harry nodded.\n",
      "8 (1073): Harry stared.\n",
      "9 (1224): “Potter, Harry!”\n",
      "10 (1352): Dear Harry,\n"
     ]
    }
   ],
   "source": [
    "for i, td in zip(range(nb_top_docs), top_docs):\n",
    "    #print(top_feats_in_doc(X_hp, features_hp, td))\n",
    "    print(\"%s (%s): %s\" % (i+1, td, lines[td]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice pour les plus courageux\n",
    "\n",
    "- choisir un corpus assez long (entre 500 et 3000 lignes)\n",
    "- découpez le corpus en textes courts (par ex. des phrases ou des paragraphes)\n",
    "- prétraitez-le de différentes manières :\n",
    "    * TF et TFxIDF\n",
    "    * taille du vocabulaire (par ex. 500 mots les plus fréquents vs. 2000 mots)\n",
    "    * avec/sans les mots-outils\n",
    "- déployer un moteur de recherche sur votre corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
