{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169e24db",
   "metadata": {},
   "source": [
    "# Introduction à la programmation Python\n",
    "\n",
    "Julien Velcin, Université Lyon 2\n",
    "\n",
    "Formation doctorale de l'UdL (2023-2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e29c8",
   "metadata": {},
   "source": [
    "Ce notebook est un exemple de traitement des données textuelles à des fins de classification binaires (2 classes uniquement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraires utilisées\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# prétraitement et évaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# différents classifieurs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour ignorer les avertissements\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f85be",
   "metadata": {},
   "source": [
    "# chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d59e6",
   "metadata": {},
   "source": [
    "Chargement des données à partir d'un fichier .csv (colonnes séparées par une tabulation = \"\\t\").\n",
    "\n",
    "Nous allons utiliser, pour la démonstration, un jeu de données contenant des propos toxiques diffusés sur Internet (cf. défi Kaggle de 2018 : https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).\n",
    "\n",
    "**Attention :** certains propos tenus dans les données peuvent choquer (insultes, racisme, etc.). Si vous le préferez, rien ne vous oblige à aller lire les textes d'origine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf6746",
   "metadata": {},
   "source": [
    "Chargez les données dans une variable *data_load* et afficher les dimensions de la table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe80481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2420a56",
   "metadata": {},
   "source": [
    "Affichez un extrait des données (fin de la table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cfec6",
   "metadata": {},
   "source": [
    "Affectez la liste des textes dans une variable *textes* et la liste des classes dans une variable *classes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c6c82",
   "metadata": {},
   "source": [
    "Affichez la distribution des valeurs pour les deux classes. Pour cela, vous pouvez utiliser la méthode *unique* de la librairie **numpy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d3e25",
   "metadata": {},
   "source": [
    "# Mise en forme des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c8ce5",
   "metadata": {},
   "source": [
    "Afin de pouvoir classer automatiquement ces données textuelles, nous allons passer par l'utilisation de la librairie **scikit-learn** et en particulier par l'outil nommé *TfidfVectorizer* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde52120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les paramètres sont un peu fixés au hasard ici\n",
    "vectorize = TfidfVectorizer(ngram_range=(1, 2), max_df=0.5, min_df=5)\n",
    "vectorize.fit(textes)\n",
    "data = vectorize.transform(textes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797838d7",
   "metadata": {},
   "source": [
    "On divise le jeu de données initial en deux sous-ensembles :\n",
    "\n",
    "- données d'entraînement ou *training set*\n",
    "- données de test (ici appelé parfois valiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain_X, subtest_X, subtrain_y, subtest_y = train_test_split(data, classes,\n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                   stratify=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifions que la stratification a bien fonctionné\n",
    "\n",
    "unique_values_a, counts_a = np.unique(subtrain_y, return_counts=True)\n",
    "unique_values_b, counts_b = np.unique(subtest_y, return_counts=True)\n",
    "\n",
    "print(f\"Jeu d'entrainement : \" + \" \".join([f\"{value}:{count}\" for value, count in zip(unique_values_a, counts_a)]))\n",
    "print(f\"Jeu de test : \" + \" \".join([f\"{value}:{count}\" for value, count in zip(unique_values_b, counts_b)]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtrain_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168c5a6",
   "metadata": {},
   "source": [
    "# Apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c771ce4",
   "metadata": {},
   "source": [
    "Nous allons tester différents algorithmes de classification supervisée qui traitent ici les textes en suivant l'hypothèse du sac de mots (BoW)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a34815",
   "metadata": {},
   "source": [
    "## Simple régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(subtrain_X, subtrain_y)\n",
    "pred_y_lr = lr.predict(subtest_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2284e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ce qui est prédit : \" + str(pred_y_lr[0:20]))\n",
    "\n",
    "print(\"La vérité : \" + str(subtest_y[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = np.sum(pred_y_lr == subtest_y) / float(len(subtest_y))\n",
    "                                       \n",
    "print(f\"Réussite en validation {res_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c1db81",
   "metadata": {},
   "source": [
    "A comparer à la réussite sur le jeu d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_lr = lr.predict(subtrain_X)\n",
    "\n",
    "res_train = np.sum(pred_y_lr == subtrain_y) / float(len(subtrain_y))\n",
    "print(f\"Réussite sur les données d'entraînement {res_train:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3d0b7",
   "metadata": {},
   "source": [
    "Deux remarques importantes à ce stade :\n",
    "\n",
    "    1. On peut observer une différence entre les deux erreurs, signe d'un sur-apprentissage (*overfitting*)\n",
    "    2. Nous avons utilisé un même nom de variable (pred_y_lr) pour deux résultats différents : c'est une mauvaise habitude et nous allons utiliser 2 variables différentes pour la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc343b",
   "metadata": {},
   "source": [
    "Concernant le sur-apprentissage, une piste serait ici de régulariser le modèle avec un terme qui pénalise une trop grande dispersion des poids (régression ridge et lasso).\n",
    "Essayons par ex. la régression ridge :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ridge = RidgeClassifier(alpha=20.0)\n",
    "lr_ridge.fit(subtrain_X, subtrain_y)\n",
    "pred_train_lr_ridge = lr_ridge.predict(subtrain_X)\n",
    "pred_test_lr_ridge = lr_ridge.predict(subtest_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffeb084",
   "metadata": {},
   "source": [
    "Le paramètre *alpha* indique la force de la régularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392accff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = np.sum(pred_train_lr_ridge == subtrain_y) / float(len(subtrain_y))\n",
    "res_test = np.sum(pred_test_lr_ridge == subtest_y) / float(len(subtest_y))\n",
    "\n",
    "print(f\"Réussite (accuracy) sur :\")\n",
    "print(f\"  - ensemble d'entraînement : {res_train:.1%}\")\n",
    "print(f\"  - ensemble de test : {res_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e145ab",
   "metadata": {},
   "source": [
    "On constate qu'on diminue le sur-apprentissage, mais au prix d'une réussite plus faible..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6000f",
   "metadata": {},
   "source": [
    "## Une évaluation plus robuste : la validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48affcec",
   "metadata": {},
   "source": [
    "Il s'agit ici d'évaluation la capacité de l'algorithme choisi à résoudre la tâche de classification.\n",
    "L'objectif est donc plus de choisir l'algorithme que de trouver le modèle lui-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(lr, subtrain_X, subtrain_y, cv=kfold)\n",
    "print(f\"Validation croisée : moyenne {results.mean():.1%} et écart-type {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040a9dd",
   "metadata": {},
   "source": [
    "Une fois l'algorithme choisi, il s'agit de réentraîner le modèle sur l'ensemble des données d'entraînement (cf. 3.1).\n",
    "\n",
    "Pour simplifier le code, on crée une fonction d'affichage des deux erreurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04eba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(nom_algo, pred_train, pred_test):\n",
    "    print(nom_algo + \" : \")\n",
    "    acc_app = np.sum(pred_train == subtrain_y) / float(len(subtrain_y))\n",
    "    print(f\"  - réussite (accuracy) apparente : {acc_app:.1%}\")\n",
    "    acc_gen = np.sum(pred_test == subtest_y) / float(len(subtest_y))\n",
    "    print(f\"  - réussite (accuracy) en généralisation : {acc_gen:.1%}\")                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c82045",
   "metadata": {},
   "source": [
    "A présent, il est possible de suivre la même méthodologie mais en changeant l'algorithme de classification. La librairie propose ainsi les classifieurs suivants :\n",
    "\n",
    "- Machines à vecteurs supports (ou SVM)\n",
    "- Arbres de décisions (en particulier XGBoost)\n",
    "- Réseaux de neurones artificiels\n",
    "- KNN\n",
    "- Naives Bayes\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e946cd",
   "metadata": {},
   "source": [
    "## Ce que vous pouvez faire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc9a29",
   "metadata": {},
   "source": [
    "* Essayez d'utiliser plusieurs de ces classifieurs en suivant le même schéma que ce que nous avons vu avec la régression logistique.\n",
    "* Une fois que vous avez des résultats obtenus par plusieurs algorithmes, résumez ces résultats sous la forme d'une table pandas.\n",
    "* Le schéma étant toujours le même (fit et predict, mesures d'évaluation), factorisez le code pour le rendre plus modulaire, si possible en externalisant le code dans un fichier .py."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
